data$cum.tan.per <- as.numeric(data$cum)
# Filtering the data to get the last time point for each treatment
data.last <- subset(data, elapsed.time == max(elapsed.time))
################################################################################################
################################################################################################
#Does acidification had any effect on total emissions?
################################################################################################
#Check normality
shapiro <- shapiro.test(data.last$cum)
shapiro # Data not normally distributed
data <- fix_colnames(data)
#Convert to numeric
data$cum.tan.per <- as.numeric(data$cum.tan.per)
data$cum.tan.per <- as.numeric(data$cum)
# Filtering the data to get the last time point for each treatment
data.last <- subset(data, elapsed.time == max(elapsed.time))
View(data.last)
# Load required libraries
library(dplyr)
library(ggplot2)
library(lme4)
library(lmerTest)
library(car)
library(emmeans)
data <- read.csv('/Users/AU775281/Documents/GitHub/Fakhar-2025-Acidification/NH3/Raw data/NH3stat.csv')
#fix data by make tittle row
fix_colnames <- function(df) {
colnames(df) <- df[1, ]
df <- df[-1, ]
return(df)
}
data <- fix_colnames(data)
View(data)
#Convert to numeric
data$cum.tan.per <- as.numeric(data$cum.tan.per)
data$cum.tan.per <- as.numeric(data$cum)
#Convert to numeric
data$cum.tan.per <- as.numeric(data$cum.tan.per)
data$cum <- as.numeric(data$cum)
# Filtering the data to get the last time point for each treatment
data.last <- subset(data, elapsed.time == max(elapsed.time))
################################################################################################
################################################################################################
#Does acidification had any effect on total emissions?
################################################################################################
#Check normality
shapiro <- shapiro.test(data.last$cum)
shapiro # Data not normally distributed
################################################################################################
################################################################################################
#Does acidification had any effect on total emissions?
################################################################################################
#Check normality
shapiro <- shapiro.test(data.last$cum.tan.per)
shapiro # Data not normally distributed
#Log-transformed
# Define a small constant to avoid log(0)
k <- 0.001
data.last <- data.last %>%
mutate(log_cum = log(cum.tan.per + k))
#Check normality og log transformed
shapiro <- shapiro.test(data.last$log_cum)
shapiro # Data still not normally distributed
#Check homogeneity log transformed
levene <- leveneTest(log_cum ~ treatment, data = data.last)
levene
#Since assumption are normally distributed we used anova
anova_model <- aov(log_cum ~ treatment, data = data.last)
summary(anova_model) #Acidification had strong effect and statistically significant
TukeyHSD(anova_model)
#HSD.test for alphbets
tukey <- HSD.test(anova_model, "treatment", group = TRUE)
tukey$groups
data$rep <- as.factor(data$rep)
#Fitting model
model1 <- lmer(tanloss.per ~ treatment * factor(time) + (1 | rep), data = data)
#Get estimated marginal means for treatment at each time point
emm <- emmeans(model1, ~ treatment | time)
#Pairwise comparisons between treatments at each time point
contrast_results <- contrast(emm, method = "pairwise", adjust = "tukey")
# Load required libraries
library(dplyr)
library(ggplot2)
library(lme4)
library(lmerTest)
library(car)
library(emmeans)
data <- read.csv('/Users/AU775281/Documents/GitHub/Fakhar-2025-Acidification/NH3/Raw data/NH3stat.csv')
#fix data by make tittle row
fix_colnames <- function(df) {
colnames(df) <- df[1, ]
df <- df[-1, ]
return(df)
}
data <- fix_colnames(data)
#Convert to numeric
data$cum.tan.per <- as.numeric(data$cum.tan.per)
# Filtering the data to get the last time point for each treatment
data.last <- subset(data, elapsed.time == max(elapsed.time))
################################################################################################
################################################################################################
#Does acidification had any effect on total emissions?
################################################################################################
#Check normality
shapiro <- shapiro.test(data.last$cum.tan.per)
shapiro # Data not normally distributed
#Log-transformed
# Define a small constant to avoid log(0)
k <- 0.001
data.last <- data.last %>%
mutate(log_cum = log(cum.tan.per + k))
#Check normality og log transformed
shapiro <- shapiro.test(data.last$log_cum)
shapiro # Data still not normally distributed
#Check homogeneity log transformed
levene <- leveneTest(log_cum ~ treatment, data = data.last)
levene
#Since assumption are normally distributed we used anova
anova_model <- aov(log_cum ~ treatment, data = data.last)
summary(anova_model) #Acidification had strong effect and statistically significant
TukeyHSD(anova_model)
#HSD.test for alphbets
tukey <- HSD.test(anova_model, "treatment", group = TRUE)
tukey$groups
data$rep <- as.factor(data$rep)
View(data)
data$id <- as.factor(data$is)
data$rep <- as.factor(data$rep)
#Fitting model
model1 <- lmer(tanloss.per ~ treatment * factor(time) + (1 | rep), data = data)
data <- read.csv('/Users/AU775281/Documents/GitHub/Fakhar-2025-Acidification/NH3/Raw data/NH3stat.csv')
#fix data by make tittle row
fix_colnames <- function(df) {
colnames(df) <- df[1, ]
df <- df[-1, ]
return(df)
}
data <- fix_colnames(data)
#Convert to numeric
data$cum.tan.per <- as.numeric(data$cum.tan.per)
# Filtering the data to get the last time point for each treatment
data.last <- subset(data, elapsed.time == max(elapsed.time))
################################################################################################
################################################################################################
#Does acidification had any effect on total emissions?
################################################################################################
#Check normality
shapiro <- shapiro.test(data.last$cum.tan.per)
shapiro # Data not normally distributed
#Log-transformed
# Define a small constant to avoid log(0)
k <- 0.001
data.last <- data.last %>%
mutate(log_cum = log(cum.tan.per + k))
#Check normality og log transformed
shapiro <- shapiro.test(data.last$log_cum)
shapiro # Data still not normally distributed
#Check homogeneity log transformed
levene <- leveneTest(log_cum ~ treatment, data = data.last)
levene
#Since assumption are normally distributed we used anova
anova_model <- aov(log_cum ~ treatment, data = data.last)
summary(anova_model) #Acidification had strong effect and statistically significant
TukeyHSD(anova_model)
#HSD.test for alphbets
tukey <- HSD.test(anova_model, "treatment", group = TRUE)
tukey$groups
data$rep <- as.factor(data$rep)
#Fitting model
model1 <- lmer(tanloss.per ~ treatment * factor(time) + (1 | rep), data = data)
#Get estimated marginal means for treatment at each time point
emm <- emmeans(model1, ~ treatment | time)
#Pairwise comparisons between treatments at each time point
contrast_results <- contrast(emm, method = "pairwise", adjust = "tukey")
data$rep <- as.factor(data$rep)
#Fitting model
model1 <- lmer(tanloss.per ~ treatment * factor(time) + (1 | rep), data = data)
#Get estimated marginal means for treatment at each time point
emm <- emmeans(model1, ~ treatment | time)
str(data)
# Convert columns to numeric
data$tanloss.per <- as.numeric(data$tanloss.per)
data$elapsed.time <- as.numeric(data$elapsed.time)
#Fitting model
model1 <- lmer(tanloss.per ~ treatment * factor(time) + (1 | rep), data = data)
data$rep <- as.factor(data$rep)
# Convert columns to numeric
data$tanloss.per <- as.numeric(data$tanloss.per)
data$elapsed.time <- as.numeric(data$elapsed.time)
#Fitting model
model1 <- lmer(tanloss.per ~ treatment * factor(time) + (1 | rep), data = data)
data <- read.csv('/Users/AU775281/Documents/GitHub/Fakhar-2025-Acidification/NH3/Raw data/NH3stat.csv')
#fix data by make tittle row
fix_colnames <- function(df) {
colnames(df) <- df[1, ]
df <- df[-1, ]
return(df)
}
data <- fix_colnames(data)
data$rep <- as.factor(data$rep)
#Fitting model
model1 <- lmer(tanloss.per ~ treatment * factor(elapsed.time) + (1 | rep), data = data)
# Convert columns to numeric
data$tanloss.per <- as.numeric(data$tanloss.per)
data$elapsed.time <- as.numeric(data$elapsed.time)
#Fitting model
model1 <- lmer(tanloss.per ~ treatment * factor(elapsed.time) + (1 | rep), data = data)
#Get estimated marginal means for treatment at each time point
emm <- emmeans(model1, ~ treatment | time)
#View summary of contrasts with significance
summary(contrast_results)
#Get estimated marginal means for treatment at each time point
emm <- emmeans(model1, ~ treatment | elapsed.time)
#Pairwise comparisons between treatments at each time point
contrast_results <- contrast(emm, method = "pairwise", adjust = "tukey")
#View summary of contrasts with significance
summary(contrast_results)
data$rep <- as.factor(data$rep)
# Convert columns to numeric
data$tanloss.per <- as.numeric(data$tanloss.per)
data$elapsed.time <- as.numeric(data$elapsed.time)
#Fitting model
model <- lmer(tanloss.per ~ treatment * factor(elapsed.time) + (1 | rep), data = data)
#Get estimated marginal means for treatment at each time point
emm <- emmeans(model, ~ treatment | elapsed.time)
# Load required libraries
library(dplyr)
library(ggplot2)
library(lme4)
library(lmerTest)
library(car)
library(emmeans)
data <- read.csv('/Users/AU775281/Documents/GitHub/Fakhar-2025-Acidification/NH3/Raw data/NH3stat.csv')
#fix data by make tittle row
fix_colnames <- function(df) {
colnames(df) <- df[1, ]
df <- df[-1, ]
return(df)
}
data <- fix_colnames(data)
#Convert to numeric
data$cum.tan.per <- as.numeric(data$cum.tan.per)
# Filtering the data to get the last time point for each treatment
data.last <- subset(data, elapsed.time == max(elapsed.time))
################################################################################################
################################################################################################
#Does acidification had any effect on total emissions?
################################################################################################
#Check normality
shapiro <- shapiro.test(data.last$cum.tan.per)
shapiro # Data not normally distributed
#Log-transformed
# Define a small constant to avoid log(0)
k <- 0.001
data.last <- data.last %>%
mutate(log_cum = log(cum.tan.per + k))
#Check normality og log transformed
shapiro <- shapiro.test(data.last$log_cum)
shapiro # Data still not normally distributed
#Check homogeneity log transformed
levene <- leveneTest(log_cum ~ treatment, data = data.last)
levene
#Since assumption are normally distributed we used anova
anova_model <- aov(log_cum ~ treatment, data = data.last)
summary(anova_model) #Acidification had strong effect and statistically significant
TukeyHSD(anova_model)
#HSD.test for alphbets
tukey <- HSD.test(anova_model, "treatment", group = TRUE)
tukey$groups
data$rep <- as.factor(data$rep)
# Convert columns to numeric
data$tanloss.per <- as.numeric(data$tanloss.per)
data$elapsed.time <- as.numeric(data$elapsed.time)
#Fitting model
model <- lmer(tanloss.per ~ treatment * factor(elapsed.time) + (1 | rep), data = data)
#Get estimated marginal means for treatment at each time point
emm <- emmeans(model, ~ treatment | elapsed.time)
#Pairwise comparisons between treatments at each time point
contrast_results <- contrast(emm, method = "pairwise", adjust = "tukey")
#View summary of contrasts with significance
summary(contrast_results)
source("~/Documents/GitHub/Fakhar-2025-Acidification/NH3/R Scripts/Stats.R")
#Library
library(dplyr)
library(agricolae)
library(multcompView)
#loading data
data <- read.csv('/Users/AU775281/Documents/GitHub/Fakhar-2025-Acidification/Slurry/Stat/Raw stat.csv')
#Get slurry parameters
paramtr <- unique(data$parameter)
#Create an empty list to store results
results <- list()
#ANOVA Loop over each parameter
for (param in paramtr) {
sub_data <- subset(data, parameter == param)
# Run ANOVA
model <- aov(value ~ treatment, data = sub_data)
# Tukey HSD
tukey <- TukeyHSD(model)
# Get letter groupings
letters <- multcompLetters4(model, tukey)
# Get means
means <- aggregate(value ~ treatment, data = sub_data, mean)
means$letters <- letters$treatment$Letters
means$parameter <- param  # Add parameter label
# Store
results[[param]] <- means
}
#Combine all results into one data frame
Anova_result <- do.call(rbind, results)
rownames(Anova_result) <- NULL
#Printing results
print(Anova_result)
rm(list = ls())
pc <- read.csv('/Users/AU775281/Documents/GitHub/Fakhar-2025-Acidification/Correlation/PC data.csv')
vars <- c("pH", "TAN", "TS", "EC", "NO3")
# Pearson correlation for NH3
nh3.res <- lapply(vars, function(v) {
cor.test(pc[[v]], pc$NH3,
alternative = "two.sided",
method = "pearson",
conf.level = 0.95)
})
names(nh3.res) <- vars
# Summarize results
nh3_summary <- data.frame(
Variable    = vars,
Correlation = sapply(nh3.res, function(x) x$estimate),
P_value     = sapply(nh3.res, function(x) x$p.value),
CI_lower    = sapply(nh3.res, function(x) x$conf.int[1]),
CI_upper    = sapply(nh3.res, function(x) x$conf.int[2])
)
print(nh3_summary)
# Pearson correlation for N2O
n2o.res <- lapply(vars, function(v) {
cor.test(pc[[v]], pc$N2O,
alternative = "two.sided",
method = "pearson",
conf.level = 0.95)
})
names(n2o.res) <- vars
# Summarize results
n2o_summary <- data.frame(
Variable    = vars,
Correlation = sapply(n2o.res, function(x) x$estimate),
P_value     = sapply(n2o.res, function(x) x$p.value),
CI_lower    = sapply(n2o.res, function(x) x$conf.int[1]),
CI_upper    = sapply(n2o.res, function(x) x$conf.int[2])
)
print(n2o_summary)
rm(list = ls())
#library
library(ggplot2)
#Importing data
acid <- read.csv('/Users/AU775281/Documents/GitHub/Fakhar-2025-Acidification/Lab/Acid level requirement.csv')
#Defining the pH selected point
x_line <- acid$mean[acid$s.no == 8]
#Making graph
lab1 <- ggplot(acid, aes(x = mean, y = acid)) +
geom_ribbon(aes(xmin = mean - std, xmax = mean + std),
fill = "#4e79a7", alpha = 0.5) +
geom_line(linewidth = 0.5, color = "#4e79a7") +
geom_point(size = 2.5, shape = 16, alpha = 1, color = "#4e79a7") +
geom_vline(xintercept = x_line, color = "#BC544B", linetype = "solid", linewidth = 0.5, alpha = 0.7) +  # Red vertical line
scale_x_continuous(breaks = seq(0, 11, by = 1)) +
scale_y_continuous(breaks = seq(0, 15, by = 2)) +
labs(
y = expression("Acid (kg ton"^{-1}*")"),
x = "Slurry pH"
) +
theme_bw() +
theme(
axis.title = element_text(size = 12),
axis.text = element_text(size = 12),
plot.title = element_text(size = 12, hjust = 0.5),
strip.text = element_text(size = 12),
legend.text = element_text(size = 12),
legend.title = element_blank(),
legend.position = "bottom",
panel.grid = element_blank()
) +
guides(color = guide_legend(nrow = 1)); lab1
#Saving graph#
#ggsave("/Users/AU775281/Documents/GitHub/Fakhar-2025-Acidification/Figures/pH.jpg",
plot = lab1,
rm(list = ls())
#Library
library(dplyr)
library(agricolae)
library(multcompView)
#loading data
data <- read.csv('/Users/AU775281/Documents/GitHub/Fakhar-2025-Acidification/Slurry/Stat/Stat data.csv')
#Get slurry parameters
paramtr <- unique(data$parameter)
#Create an empty list to store results
results <- list()
#ANOVA Loop over each parameter
for (param in paramtr) {
sub_data <- subset(data, parameter == param)
# Run ANOVA
model <- aov(value ~ treatment, data = sub_data)
# Tukey HSD
tukey <- TukeyHSD(model)
# Get letter groupings
letters <- multcompLetters4(model, tukey)
# Get means
means <- aggregate(value ~ treatment, data = sub_data, mean)
means$letters <- letters$treatment$Letters
means$parameter <- param  # Add parameter label
# Store
results[[param]] <- means
}
#Combine all results into one data frame
Anova_result <- do.call(rbind, results)
rownames(Anova_result) <- NULL
#Printing results
print(Anova_result)
rm(list = ls())
library(ggplot2)
library(readxl)
library(tidyr)
library(dplyr)
library(ggbreak)
library(patchwork)
# Read and format data
daily <- read.csv("//Users/AU775281/Documents/GitHub/Fakhar-2025-Acidification/Weather/Daily.csv")
hourly <- read.csv("/Users/AU775281/Documents/GitHub/Fakhar-2025-Acidification/Weather/weatherhour.csv")
hourly <- hourly[!duplicated(hourly$elapsed.time), ]
#change date format
daily$date <- gsub("(\\d{1,2}/\\d{1,2}/)(\\d{2})$", "\\120\\2", daily$date)
daily$date <- as.Date(daily$date, format = "%d/%m/%Y")
# Define NH3 exp starting and ending point
x_line <- as.Date("2025-07-04")
nh3_start <- as.Date("2025-06-30")
nh3_end <- as.Date("2025-07-04")
# Plot
dailyplot <- ggplot(daily, aes(x = date)) +
geom_col(aes(y = prec, fill = "Precipitation"), alpha = 0.7, width = 0.6) +
geom_line(aes(y = temp, color = "Temperature"), linewidth = 0.8) +
geom_point(aes(y = temp, color = "Temperature"), size = 2) +
annotate("text", x = nh3_start + 1, y = max(daily$temp, na.rm = TRUE),
label = "NH3 Period", hjust = 0.5, vjust = -2, size = 3, fontface = "bold", color = "gray30") +
geom_vline(xintercept = x_line, color = "#BC544B", linetype = "solid", size = 0.5, alpha = 0.7) +
scale_y_continuous(
name = "Temperature (°C)",
breaks = seq(0, 30, by = 5)
) +
scale_x_date(date_breaks = "5 days", date_labels = "%d-%m") +
scale_color_manual(name = NULL, values = c("Temperature" = "#f28e2b")) +
scale_fill_manual(name = NULL, values = c("Precipitation" = "#4e79a7")) +
labs(x = "Date") +
theme_bw() +
theme(
#axis.text.x = element_text(angle = 45, hjust = 0.5, vjust = 0.5),
axis.title.y.right = element_blank(),
axis.text.y.right = element_blank(),
axis.ticks.y.right = element_blank(),
axis.title = element_text(size = 12),
axis.text = element_text(size = 12),
plot.title = element_text(size = 14, hjust = 0.5),
strip.text = element_text(size = 12),
legend.text = element_text(size = 12),
legend.title = element_blank(),
legend.position = "none",
panel.grid = element_blank()
) +
guides(
color = guide_legend(order = 1),
fill = guide_legend(order = 2, override.aes = list(alpha = 0.7))
); dailyplot
#Highlight NH3 period on daily plot:
dailyplot2 <- dailyplot +
annotate("rect",
xmin = nh3_start, xmax = nh3_end,
ymin = -Inf, ymax = Inf,
alpha = 0.2, fill = "gray") +
geom_vline(xintercept = x_line, color = "#BC544B", linetype = "solid", size = 0.5, alpha = 0.7)
# Plot
dailyplot <- ggplot(daily, aes(x = date)) +
geom_col(aes(y = prec, fill = "Precipitation"), alpha = 0.7, width = 0.6) +
geom_line(aes(y = temp, color = "Temperature"), linewidth = 0.8) +
geom_point(aes(y = temp, color = "Temperature"), size = 2) +
annotate("text", x = nh3_start + 1, y = max(daily$temp, na.rm = TRUE),
label = "NH3 Period", hjust = 0.5, vjust = -2, size = 3, fontface = "bold", color = "gray30") +
geom_vline(xintercept = x_line, color = "#BC544B", linetype = "solid", linewidth = 0.5, alpha = 0.7) +
scale_y_continuous(
name = "Temperature (°C)",
breaks = seq(0, 30, by = 5)
) +
scale_x_date(date_breaks = "5 days", date_labels = "%d-%m") +
scale_color_manual(name = NULL, values = c("Temperature" = "#f28e2b")) +
scale_fill_manual(name = NULL, values = c("Precipitation" = "#4e79a7")) +
labs(x = "Date") +
theme_bw() +
theme(
#axis.text.x = element_text(angle = 45, hjust = 0.5, vjust = 0.5),
axis.title.y.right = element_blank(),
axis.text.y.right = element_blank(),
axis.ticks.y.right = element_blank(),
axis.title = element_text(size = 12),
axis.text = element_text(size = 12),
plot.title = element_text(size = 14, hjust = 0.5),
strip.text = element_text(size = 12),
legend.text = element_text(size = 12),
legend.title = element_blank(),
legend.position = "none",
panel.grid = element_blank()
) +
guides(
color = guide_legend(order = 1),
fill = guide_legend(order = 2, override.aes = list(alpha = 0.7))
); dailyplot
